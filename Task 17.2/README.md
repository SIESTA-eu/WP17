<div align="justify">This subfolder contains the codes for NER-based text anonymization experiments. To run the codes, the dependencies need to be installed using the "install.sh" bash file. Fourteen pretrained models have been used. The individual pretrained models need to changed as desired. The entity categories in the pretrained models and the experimental dataset (CECILIA) have been unified. For information about and access to CECILIA dataset used, kindly consult this [page](https://gvis.unileon.es/datasets-cecilia-10c-900-ner/)</div>
The pretrained models include:
1. dslim/bert-base-NER
2. dslim/bert-large-NER
3. dbmdz/bert-base-cased-finetuned-conll03-english
4. dbmdz/bert-large-cased-finetuned-conll03-english
5. elastic/distilbert-base-uncased-finetuned-conll03-english
6. Davlan/xlm-roberta-base-ner-hrl
7. xlm-roberta-large-finetuned-conll03-english
8. Jean-Baptiste/roberta-large-ner-english
9. Davlan/xlm-roberta-large-ner-hrl
10. Davlan/bert-base-multilingual-cased-ner-hrl
11. spacy/en_core_web_sm
12. spacy/en_core_web_md
13. spacy/en_core_web_lg
14. spacy/en_core_web_trf
